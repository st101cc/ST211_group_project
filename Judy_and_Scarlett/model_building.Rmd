---
title: "model"
author: "Scarlett"
date: "2024-04-08"
output: html_document
---
# Set up
```{r message=FALSE, warning=FALSE}
#rm(list=ls())
library(arm)
library(ggplot2)
library(dplyr)
library(tidyr)
library(gridExtra)
library(car)
```

# Load data

In this dataset, missing values are coded as NA for continuous variables and set as a new level for categorical variables.

```{r message=FALSE, warning=FALSE}
data<-read.csv("../data/W8DINCW_newlevel.csv",header = TRUE, stringsAsFactors=TRUE)
```

Convert the categorical variables to factors:
```{r message=FALSE, warning=FALSE}
exclude_vars <- c("X", "W1GrssyrMP", "W1GrssyrHH", "W1yschat1", "W2ghq12scr", "W4schatYP", "W6DebtattYP", "W8DINCW", "W8DGHQSC")

data <- data %>%
  mutate(across(where(is.integer) & !all_of(exclude_vars), factor))
```

# Model 1
By running single regression on all predictors in EDA process, we can now use the variables that are significant at 0.05 level to build the first model. (See appendix)

**appendix:**
Predcitors that are significant at 0.05 level by running single regression on all predictors:

-   Categorical Variables that are significant to the model(p-value < 0.05):

W1wrk1aMP, W1condur5MP, W1hea2MP, W1NoldBroHS, W1hous12HH, W1usevcHH,
W1hiqualdad, W1hiqualmum, W1wrkfulldad, W1wrkfullmum, W1empsmum, W1empsdad,
W1ch0_2HH, W1ch3_11HH, IndSchool, W1marstatmum, W1depkids, W1famtyp2,
W1nssecfam, W1ethgrpYP, W1heposs9YP(), W1hwndayYP(), W1truantYP, W1alceverYP,
W1bulrc, W1disabYP, W2disc1YP, W2depressYP(), W4AlcFreqYP(only 2 levels are significant), W4CannTryYP,
W4NamesYP(), W4RacismYP, W4empsYP(),W4Childck1YP(overwhelmingly missing data), W5JobYP, W5JobYP, 
W5EducYP, W5Apprent1YP, W6JobYP, W6UnivYP, W6EducYP, W6Apprent1YP(),
W6acqno, W6gcse(), W6als(more significant than w6gcse), W6OwnchiDV, W6Childliv, W6NEETAct(the only significant level is missing level),
W8DDEGP, W8TENURE

-   Continuous Varaibles that are significant to the model(p-value < 0.05):

W2ghq12scr(), W4schatYP(), W6DebtattYP
**over**

```{r message=FALSE, warning=FALSE}
sig.var <- c("W1wrk1aMP", 'W1condur5MP', 'W1hea2MP', 'W1NoldBroHS', 'W1hous12HH', 'W1usevcHH', 'W1hiqualdad', 'W1hiqualmum', 'W1wrkfulldad', 'W1wrkfullmum', 'W1empsmum', 'W1empsdad', 'W1ch0_2HH', 'W1ch3_11HH', 'IndSchool', 'W1marstatmum', 'W1depkids', 'W1famtyp2', 'W1nssecfam', 'W1ethgrpYP', 'W1heposs9YP', 'W1hwndayYP', 'W1truantYP', 'W1alceverYP', 'W1bulrc', 'W1disabYP', 'W2disc1YP', 'W2depressYP', 'W4AlcFreqYP', 'W4CannTryYP', 'W4NamesYP', 'W4RacismYP', 'W4empsYP','W4Childck1YP', 'W5JobYP', 'W5JobYP', 'W5EducYP', 'W5Apprent1YP', 'W6JobYP', 'W6UnivYP', 'W6EducYP', 'W6Apprent1YP', 'W6acqno', 'W6gcse', 'W6als', 'W6OwnchiDV', 'W6Childliv', 'W6NEETAct', 'W8DDEGP', 'W8TENURE', 'W2ghq12scr', 'W4schatYP', 'W6DebtattYP')


#Create the formula string
formula_str <- paste("W8DINCW ~", paste(sig.var, collapse = " + "))
#Convert the string to a formula object
formula_obj <- as.formula(formula_str)
model.1 <- lm(formula_obj, data = data)

display(model.1)
```
From the first initial model, we now only keep the predictors that are significant at 0.05 level (See appendix). After removing non-significant predictors, there are 23 of them left in the model.

**appendix:**
Predictors that are left after the first model based on their significance level:

-   Categorical predictors:
W1hea2MP, W1NoldBroHS, W1hous12HH, W1hiqualmum, W1marstatmum, W1depkids, W1nssecfam, W1ethgrpYP, W1heposs9YP, W1hwndayYP, W1disabYP, W2disc1YP, W4CannTryYP, W5JobYP, W5EducYP, W5Apprent1YP, W6JobYP, W6UnivYP, W6Apprent1YP, W6NEETAct, W8TENURE

-   Continuous predictors:
W2ghq12scr, W4schatYP
**over**

Some inner merges within categorical variables are done to reduce the number of levels in the variables. Based on the boxplots we produced, we combined categories that are non-significant and similar in boxplots.(See appendix)

**appendix:**
Categories in each predictor that are merged based on boxplots:

| Predictor | Merged categories |
| --- | --- |
| W1hous12HH | 4, 5 |
| W1hiqualmum | 3, 4 |
| W1hiqualmum | 5, 6, 7 |
| W1hiqualmum | 8, 9 |
| W1hiqualmum | 12, 13, 14 |
| W1marstatmum | 4, 5, 6 |

**over**

## Data Cleaning after model 1

```{r message=FALSE, warning=FALSE}
merged_data <- data  # create a copy for modifications

merged_data <- merged_data %>%
  mutate(
    #W1hous12HH, merge levels 4 and 5
    W1hous12HH = as.character(W1hous12HH),  # convert to character to avoid issues with factor levels
    W1hous12HH = if_else(W1hous12HH %in% c("4", "5"), "4_5", W1hous12HH),
    
    # W1hiqualmum, merge several groups of levels
    W1hiqualmum = as.character(W1hiqualmum),
    W1hiqualmum = case_when(
      W1hiqualmum %in% c("3", "4") ~ "3_4",
      W1hiqualmum %in% c("5", "6", "7") ~ "5_6_7",
      W1hiqualmum %in% c("8", "9") ~ "8_9",
      W1hiqualmum %in% c("12", "13", "14") ~ "12_13_14",
      TRUE ~ as.character(W1hiqualmum)
    ),
    
    # for W1marstatmum, merge levels 4, 5 and 6
    W1marstatmum = as.character(W1marstatmum),
    W1marstatmum = if_else(W1marstatmum %in% c("4", "5", "6"), "4_5_6", W1marstatmum)
  ) %>%
  mutate(
    # convert back to factors with new levels
    W1hous12HH = factor(W1hous12HH),
    W1hiqualmum = factor(W1hiqualmum),
    W1marstatmum = factor(W1marstatmum)
  )

# dropping unused factor levels
data <- data %>%
  mutate(
    W1hous12HH = droplevels(W1hous12HH),
    W1hiqualmum = droplevels(W1hiqualmum),
    W1marstatmum = droplevels(W1marstatmum)
  )


#summary(merged_data)
```

# Model 2
After the data cleaning process, we now build the second model with the predictors left.

```{r message=FALSE, warning=FALSE}
sig.var_2 <- c("W1hea2MP", "W1NoldBroHS", "W1hous12HH", "W1hiqualmum", "W1marstatmum", "W1depkids", "W1nssecfam", "W1ethgrpYP", "W1heposs9YP", "W1hwndayYP", "W1disabYP", "W2disc1YP", "W4CannTryYP", "W5JobYP", "W5EducYP", "W5Apprent1YP", "W6JobYP", "W6UnivYP", "W6Apprent1YP", "W6NEETAct", "W8TENURE", "W2ghq12scr", "W4schatYP")

#Create the formula string
formula_str <- paste("W8DINCW ~", paste(sig.var_2, collapse = " + "))
#Convert the string to a formula object
formula_obj <- as.formula(formula_str)
model.2 <- lm(formula_obj, data = merged_data)

display(model.2)
```
Again, there are still too many predictors and some of them are not significant in this model. We then removed these non-significant predictors here. (See appendix) After removing, there are 20 of them left in the model.

**appendix:**
Predictors that are left after the second model based on their significance level:

"W1hea2MP", "W1hous12HH", "W1hiqualmum", "W1marstatmum", "W1depkids", "W1nssecfam", "W1ethgrpYP", "W1heposs9YP", "W1hwndayYP", "W1disabYP", "W2disc1YP", "W4CannTryYP", "W5JobYP", "W5EducYP", "W5Apprent1YP", "W6JobYP", "W6UnivYP", "W6Apprent1YP", "W6NEETAct", "W2ghq12scr"

**over**

# Model 3
After the data cleaning process, we now build the third model with the predictors left.

```{r message=FALSE, warning=FALSE}
sig.var_3 <- c("W1hea2MP", "W1hous12HH", "W1hiqualmum", "W1marstatmum", "W1depkids", "W1nssecfam", "W1ethgrpYP", "W1heposs9YP", "W1hwndayYP", "W1disabYP", "W2disc1YP", "W4CannTryYP", "W5JobYP", "W5EducYP", "W5Apprent1YP", "W6JobYP", "W6UnivYP", "W6Apprent1YP", "W6NEETAct", "W2ghq12scr")

#Create the formula string
formula_str <- paste("W8DINCW ~", paste(sig.var_3, collapse = " + "))
#Convert the string to a formula object
formula_obj <- as.formula(formula_str)
model.3 <- lm(formula_obj, data = merged_data)

display(model.3)
```
From the results, we noticed that the missing level in `W6Apprent1YP` shows NA in estimations, which could be due to perfect multicollienarity. When removing this level, R reported an error indicating that another categorical variable became a single-level factor due to the absence of rows that have `W6Apprent1YPmissing` value. Thus, we could identify that perfect multicollinearity exists between `W6Apprent1YPmissing` and another predictor. To ensure independence, we decided to remove the whole `W6Apprent1YP`.

# Model 4 - Check for multicollinearity

```{r message=FALSE, warning=FALSE}
sig.var_4 <- c("W1hea2MP", "W1hous12HH", "W1hiqualmum", "W1marstatmum", "W1depkids", "W1nssecfam", "W1ethgrpYP", "W1heposs9YP", "W1hwndayYP", "W1disabYP", "W2disc1YP", "W4CannTryYP", "W5JobYP", "W5EducYP", "W5Apprent1YP", "W6JobYP", "W6UnivYP", "W6NEETAct", "W2ghq12scr")

#Create the formula string
formula_str <- paste("W8DINCW ~", paste(sig.var_4, collapse = " + "))
#Convert the string to a formula object
formula_obj <- as.formula(formula_str)
model.4 <- lm(formula_obj, data = merged_data)

#display(model.4)

vif(model.4)
```
After removing the `W6Apprent1YP` predictor, we did a VIF test to check for multicollinearity. Here to ensure the independence of predictors, we followed the rule of thumb that VIF values should be less than 10. Therefore we removed `W1hiqualmum` with the vif value of 13.


# Remove non-significant categories
There are some categorical predictors with only one or two significant categories. We first placed these predictors in ascending order by their significance, tried to remove each categorical predictor by order, and then run each regression to see if the model is improved by comparing the R-squared value. (See appendix)

As a result, we removed `W1hous12HH` and `W6NEETAct`, since they only have one significant category and their removal did not affect the R-squared value. It's reasonable to remove them, since the predictors with only one significant category are not informative for the model.

1. Original R-squared: 0.66
```{r message=FALSE, warning=FALSE}
kept_var <- c("W1hea2MP", "W1hous12HH", "W1marstatmum", "W1depkids", "W1nssecfam", "W1ethgrpYP", "W1heposs9YP", "W1hwndayYP", "W1disabYP", "W2disc1YP", "W4CannTryYP", "W5JobYP", "W5EducYP", "W5Apprent1YP", "W6JobYP", "W6UnivYP", "W6NEETAct", "W2ghq12scr")

#Create the formula string
formula_str <- paste("W8DINCW ~", paste(kept_var, collapse = " + "))
#Convert the string to a formula object
formula_obj <- as.formula(formula_str)
model.5 <- lm(formula_obj, data = merged_data)

display(model.5)
```
2. Remove W1hous12HH
```{r message=FALSE, warning=FALSE}
kept_var <- c("W1hea2MP", "W1marstatmum", "W1depkids", "W1nssecfam", "W1ethgrpYP", "W1heposs9YP", "W1hwndayYP", "W1disabYP", "W2disc1YP", "W4CannTryYP", "W5JobYP", "W5EducYP", "W5Apprent1YP", "W6JobYP", "W6UnivYP", "W6NEETAct", "W2ghq12scr")

#Create the formula string
formula_str <- paste("W8DINCW ~", paste(kept_var, collapse = " + "))
#Convert the string to a formula object
formula_obj <- as.formula(formula_str)
model.6 <- lm(formula_obj, data = merged_data)

display(model.6)
```
3. remove W6NEETAct
```{r message=FALSE, warning=FALSE}
kept_var <- c("W1hea2MP", "W1marstatmum", "W1depkids", "W1nssecfam", "W1ethgrpYP", "W1heposs9YP", "W1hwndayYP", "W1disabYP", "W2disc1YP", "W4CannTryYP", "W5JobYP", "W5EducYP", "W5Apprent1YP", "W6JobYP", "W6UnivYP", "W2ghq12scr")

#Create the formula string
formula_str <- paste("W8DINCW ~", paste(kept_var, collapse = " + "))
#Convert the string to a formula object
formula_obj <- as.formula(formula_str)
model.7 <- lm(formula_obj, data = merged_data)

display(model.7) # the final model in this section
```
3. remove W1depkids
```{r message=FALSE, warning=FALSE}
kept_var <- c("W1hea2MP", "W1marstatmum", "W1nssecfam", "W1ethgrpYP", "W1heposs9YP", "W1hwndayYP", "W1disabYP", "W2disc1YP", "W4CannTryYP", "W5JobYP", "W5EducYP", "W5Apprent1YP", "W6JobYP", "W6UnivYP", "W2ghq12scr")

#Create the formula string
formula_str <- paste("W8DINCW ~", paste(kept_var, collapse = " + "))
#Convert the string to a formula object
formula_obj <- as.formula(formula_str)
model.8 <- lm(formula_obj, data = merged_data)

display(model.8)
```
**appendix:**
A table with removed categorical predictors and the resulted R-squared values (predictors are listed in order of their p-values from model 4):

| Categorical Predictors | Number of significant categories | Resulted R-squared | Decision |
| --- | --- | --- | --- |
| Original R-squared | | 0.66 | |
| W1hous12HH | 1 | 0.66 | remove |
| W6NEETAct | 1 | 0.66 | remove |
| W1depkids| 3 | 0.65 | keep |

**over**

# Model 9 - Combine some levels
There are still too many predictors and we therefore combine some levels in the categorical predictors to reduce the number of predictors based on similar coefficients. (See appendix)

**appendix:**
Categories in each predictor that are merged based on similar coefficients:
| Predictor | Merged categories |
| --- | --- |
| W1depkids | (1, 2, 3) |
| W1nssecfam | (1, 2) / (3, 4, 5) / (6, 7) |
| W1ethgrpYP | (2, 3) / (6, 7, 8) |
| W1hwndayYP | (2, 3) |
**over**

```{r message=FALSE, warning=FALSE}
merged_data <- merged_data %>%
  mutate(
    W1depkids = as.character(W1depkids),
    W1depkids = if_else(W1depkids %in% c("1", "2", "3"), "1_2_3", W1depkids),
    
    W1nssecfam = as.character(W1nssecfam),
    W1nssecfam = case_when(
      W1nssecfam %in% c("1", "2") ~ "1_2",
      W1nssecfam %in% c("3", "4", "5") ~ "3_4_5",
      W1nssecfam %in% c("6", "7") ~ "6_7",
      TRUE ~ as.character(W1nssecfam)
    ),
    
    W1ethgrpYP = as.character(W1ethgrpYP),
    W1ethgrpYP = case_when(
      W1ethgrpYP %in% c("2", "3") ~ "2_3",
      W1ethgrpYP %in% c("6", "7", "8") ~ "6_7_8",
      TRUE ~ as.character(W1ethgrpYP)
    ),

    W1hwndayYP = as.character(W1hwndayYP),
    W1hwndayYP = if_else(W1hwndayYP %in% c("2", "3"), "2_3", W1hwndayYP)
  ) %>%
  
  mutate(
    # convert back to factors with new levels
    W1depkids = factor(W1depkids),
    W1nssecfam = factor(W1nssecfam),
    W1ethgrpYP = factor(W1ethgrpYP),
    W1hwndayYP = factor(W1hwndayYP)
  )

# dropping unused factor levels
data <- data %>%
  mutate(
    W1depkids = droplevels(W1depkids),
    W1nssecfam = droplevels(W1nssecfam),
    W1ethgrpYP = droplevels(W1ethgrpYP),
    W1hwndayYP = droplevels(W1hwndayYP)
  )

kept_var <- c("W1hea2MP", "W1marstatmum", "W1depkids", "W1nssecfam", "W1ethgrpYP", "W1heposs9YP", "W1hwndayYP", "W1disabYP", "W2disc1YP", "W4CannTryYP", "W5JobYP", "W5EducYP", "W5Apprent1YP", "W6JobYP", "W6UnivYP", "W2ghq12scr")

#Create the formula string
formula_str <- paste("W8DINCW ~", paste(kept_var, collapse = " + "))
#Convert the string to a formula object
formula_obj <- as.formula(formula_str)
model.9 <- lm(formula_obj, data = merged_data)

display(model.9)
```

# Model 10 - remove one non-significant predictor
From the results of model 9, we noticed that the predictor `W1depkids` is not significant in the model. Its removal did not affect the R-squared value. Therefore, we removed it for the final model.

```{r}
kept_var <- c("W1hea2MP", "W1marstatmum", "W1nssecfam", "W1ethgrpYP", "W1heposs9YP", "W1hwndayYP", "W1disabYP", "W2disc1YP", "W4CannTryYP", "W5JobYP", "W5EducYP", "W5Apprent1YP", "W6JobYP", "W6UnivYP", "W2ghq12scr")

#Create the formula string
formula_str <- paste("W8DINCW ~", paste(kept_var, collapse = " + "))
#Convert the string to a formula object
formula_obj <- as.formula(formula_str)
model.10 <- lm(formula_obj, data = merged_data)

display(model.10)
```

# Check for interaction
There are already many predictors in the existing model, thus adding interactions will make the model more complex and harder to interpret. We decided not to add interactions in this model.

# Missing value analysis
For current model, the predictors we included have no missing values. We have already removed the predictors with missing values in the model building process.

# Model diagnostics
```{r}
par(mfrow=c(2,2))
plot(model.10,which=c(1,2))
hist(model.10$residuals,main="Histogram of residuals",font.main=1,xlab="Residuals")
```


# Remove outliers

Apply function from lecture

```{r}
show_outliers<-function(the.linear.model,topN){
  #length of data
  n=length(fitted(the.linear.model))
  #number of parameters estimated
  p=length(coef(the.linear.model))
  #standardised residuals over 3
  res.out<-which(abs(rstandard(the.linear.model))>3) #sometimes >2
  #topN values
  res.top<-head(rev(sort(abs(rstandard(the.linear.model)))),topN)
  #high leverage values
  lev.out<-which(lm.influence(the.linear.model)$hat>2*p/n)
  #topN values
  lev.top<-head(rev(sort(lm.influence(the.linear.model)$hat)),topN)
  #high diffits
  dffits.out<-which(dffits(the.linear.model)>2*sqrt(p/n))
  #topN values
  dffits.top<-head(rev(sort(dffits(the.linear.model))),topN)
  #Cook's over 1
  cooks.out<-which(cooks.distance(the.linear.model)>1)
  #topN cooks
  cooks.top<-head(rev(sort(cooks.distance(the.linear.model))),topN)
  #Create a list with the statistics -- cant do a data frame as different lengths 
  list.of.stats<-list(Std.res=res.out,Std.res.top=res.top, Leverage=lev.out, Leverage.top=lev.top, DFFITS=dffits.out, DFFITS.top=dffits.top, Cooks=cooks.out,Cooks.top=cooks.top)
  #return the statistics
  list.of.stats}
```

```{r}
#Get outliers
outliers <- show_outliers(model.10, topN = 5) 

# Combine all outlier indices into a single vector
all_outliers <- unique(c(outliers$Std.res, outliers$Leverage, outliers$DFFITS, outliers$Cooks))

# Remove outliers from the dataset
cleaned_data <- merged_data[-all_outliers, ]
```

```{r}
kept_var <- c("W1hea2MP", "W1marstatmum", "W1nssecfam", "W1ethgrpYP", "W1heposs9YP", "W1hwndayYP", "W1disabYP", "W2disc1YP", "W4CannTryYP", "W5JobYP", "W5EducYP", "W5Apprent1YP", "W6JobYP", "W6UnivYP", "W2ghq12scr")

#Create the formula string
formula_str <- paste("W8DINCW ~", paste(kept_var, collapse = " + "))
#Convert the string to a formula object
formula_obj <- as.formula(formula_str)
model.11 <- lm(formula_obj, data = cleaned_data)

display(model.11)
```
```{r}
par(mfrow=c(2,2))
plot(model.11,which=c(1,2))
hist(model.11$residuals,main="Histogram of residuals",font.main=1,xlab="Residuals")
```

We removed the outliers from the dataset and built a model to compare. The results show that the R-squared value is 0.65, which is the 0.01 lower than the previous model (0.66). However, the the residual standard error is improved from 41.58 to 40.29. The residual plot is also improved, with the residuals more evenly distributed around 0. Therefore, we can conclude that these outliers are biased information and we should remove them from our model.

